#!/usr/bin/env python3
"""
éªŒè¯ä¸‹è½½çš„5å¹´å†å²æ•°æ®
"""

import os
import pandas as pd
from pathlib import Path
from datetime import datetime, timedelta

def verify_akshare_data():
    """éªŒè¯akshareæ•°æ®"""
    print("ğŸ” éªŒè¯akshareä¸‹è½½çš„æ•°æ®")
    print("=" * 40)
    
    data_dir = Path("data/akshare_data")
    
    if not data_dir.exists():
        print("âŒ akshareæ•°æ®ç›®å½•ä¸å­˜åœ¨")
        return False
    
    # è·å–æ‰€æœ‰CSVæ–‡ä»¶
    csv_files = list(data_dir.glob("*.csv"))
    print(f"ğŸ“Š æ‰¾åˆ° {len(csv_files)} ä¸ªè‚¡ç¥¨æ•°æ®æ–‡ä»¶")
    
    if len(csv_files) == 0:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°æ•°æ®æ–‡ä»¶")
        return False
    
    # åˆ†ææ•°æ®è´¨é‡
    total_records = 0
    valid_files = 0
    date_ranges = []
    
    print("\nğŸ“ˆ æ•°æ®è´¨é‡åˆ†æ:")
    
    for i, csv_file in enumerate(csv_files[:10]):  # æ£€æŸ¥å‰10ä¸ªæ–‡ä»¶
        try:
            df = pd.read_csv(csv_file)
            
            if len(df) > 0:
                stock_code = csv_file.stem
                record_count = len(df)
                total_records += record_count
                valid_files += 1
                
                # æ£€æŸ¥æ—¥æœŸèŒƒå›´
                if 'æ—¥æœŸ' in df.columns:
                    df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
                    start_date = df['æ—¥æœŸ'].min()
                    end_date = df['æ—¥æœŸ'].max()
                    date_ranges.append((start_date, end_date))
                    
                    # è®¡ç®—æ•°æ®è·¨åº¦
                    data_span = (end_date - start_date).days
                    
                    print(f"âœ… {stock_code}: {record_count} æ¡è®°å½•, {data_span} å¤©")
                    print(f"   æ—¶é—´èŒƒå›´: {start_date.strftime('%Y-%m-%d')} åˆ° {end_date.strftime('%Y-%m-%d')}")
                    
                    # æ£€æŸ¥æ•°æ®å®Œæ•´æ€§
                    required_columns = ['å¼€ç›˜', 'æ”¶ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æˆäº¤é‡', 'æˆäº¤é¢']
                    missing_cols = [col for col in required_columns if col not in df.columns]
                    
                    if missing_cols:
                        print(f"   âš ï¸ ç¼ºå°‘åˆ—: {missing_cols}")
                    else:
                        print(f"   âœ… æ•°æ®åˆ—å®Œæ•´")
                        
                        # æ£€æŸ¥æ•°æ®èŒƒå›´
                        current_price = df['æ”¶ç›˜'].iloc[-1]
                        price_range = f"{df['æ”¶ç›˜'].min():.2f} - {df['æ”¶ç›˜'].max():.2f}"
                        print(f"   ğŸ’° å½“å‰ä»·æ ¼: Â¥{current_price:.2f}, å†å²èŒƒå›´: Â¥{price_range}")
                else:
                    print(f"âš ï¸ {stock_code}: ç¼ºå°‘æ—¥æœŸåˆ—")
            else:
                print(f"âŒ {csv_file.name}: ç©ºæ–‡ä»¶")
                
        except Exception as e:
            print(f"âŒ {csv_file.name}: è¯»å–å¤±è´¥ - {str(e)}")
    
    # æ€»ä½“ç»Ÿè®¡
    print(f"\nğŸ“Š æ€»ä½“ç»Ÿè®¡:")
    print(f"âœ… æœ‰æ•ˆæ–‡ä»¶: {valid_files}/{len(csv_files)}")
    print(f"ğŸ“ˆ æ€»è®°å½•æ•°: {total_records:,}")
    
    if date_ranges:
        overall_start = min(start for start, end in date_ranges)
        overall_end = max(end for start, end in date_ranges)
        overall_span = (overall_end - overall_start).days
        
        print(f"ğŸ“… æ•°æ®æ—¶é—´è·¨åº¦: {overall_span} å¤© ({overall_span/365:.1f} å¹´)")
        print(f"ğŸ“… æ•°æ®èŒƒå›´: {overall_start.strftime('%Y-%m-%d')} åˆ° {overall_end.strftime('%Y-%m-%d')}")
        
        # æ£€æŸ¥æ˜¯å¦æ»¡è¶³5å¹´è¦æ±‚
        if overall_span >= 5 * 365:
            print("âœ… æ»¡è¶³5å¹´ä»¥ä¸Šå†å²æ•°æ®è¦æ±‚")
        else:
            print(f"âš ï¸ æ•°æ®è·¨åº¦ä¸è¶³5å¹´ï¼Œå½“å‰ä¸º {overall_span/365:.1f} å¹´")
    
    return valid_files > 0

def analyze_sample_stock():
    """åˆ†ææ ·æœ¬è‚¡ç¥¨æ•°æ®"""
    print("\nğŸ” è¯¦ç»†åˆ†ææ ·æœ¬è‚¡ç¥¨ (000001 å¹³å®‰é“¶è¡Œ)")
    print("=" * 40)
    
    sample_file = Path("data/akshare_data/000001.csv")
    
    if not sample_file.exists():
        print("âŒ æ ·æœ¬æ–‡ä»¶ä¸å­˜åœ¨")
        return False
    
    try:
        df = pd.read_csv(sample_file)
        df['æ—¥æœŸ'] = pd.to_datetime(df['æ—¥æœŸ'])
        df = df.sort_values('æ—¥æœŸ')
        
        print(f"ğŸ“Š æ•°æ®æ¦‚è§ˆ:")
        print(f"   è®°å½•æ•°: {len(df)}")
        print(f"   æ—¶é—´èŒƒå›´: {df['æ—¥æœŸ'].min().strftime('%Y-%m-%d')} åˆ° {df['æ—¥æœŸ'].max().strftime('%Y-%m-%d')}")
        print(f"   æ•°æ®è·¨åº¦: {(df['æ—¥æœŸ'].max() - df['æ—¥æœŸ'].min()).days} å¤©")
        
        print(f"\nğŸ’° ä»·æ ¼ç»Ÿè®¡:")
        print(f"   å½“å‰ä»·æ ¼: Â¥{df['æ”¶ç›˜'].iloc[-1]:.2f}")
        print(f"   å†å²æœ€é«˜: Â¥{df['æœ€é«˜'].max():.2f}")
        print(f"   å†å²æœ€ä½: Â¥{df['æœ€ä½'].min():.2f}")
        print(f"   å¹³å‡ä»·æ ¼: Â¥{df['æ”¶ç›˜'].mean():.2f}")
        
        print(f"\nğŸ“ˆ æˆäº¤é‡ç»Ÿè®¡:")
        print(f"   å¹³å‡æˆäº¤é‡: {df['æˆäº¤é‡'].mean():,.0f}")
        print(f"   æœ€å¤§æˆäº¤é‡: {df['æˆäº¤é‡'].max():,.0f}")
        print(f"   å¹³å‡æˆäº¤é¢: Â¥{df['æˆäº¤é¢'].mean():,.0f}")
        
        # æ£€æŸ¥æ•°æ®è¿ç»­æ€§
        df['æ—¥æœŸ_diff'] = df['æ—¥æœŸ'].diff().dt.days
        gaps = df[df['æ—¥æœŸ_diff'] > 3]  # è¶…è¿‡3å¤©çš„é—´éš”
        
        if len(gaps) > 0:
            print(f"\nâš ï¸ å‘ç° {len(gaps)} ä¸ªæ•°æ®é—´éš”:")
            for idx, row in gaps.head(5).iterrows():
                print(f"   {row['æ—¥æœŸ'].strftime('%Y-%m-%d')}: é—´éš” {row['æ—¥æœŸ_diff']} å¤©")
        else:
            print(f"\nâœ… æ•°æ®è¿ç»­æ€§è‰¯å¥½ï¼Œæ— æ˜æ˜¾é—´éš”")
        
        # æ˜¾ç¤ºæœ€è¿‘å‡ å¤©çš„æ•°æ®
        print(f"\nğŸ“… æœ€è¿‘5å¤©æ•°æ®:")
        recent_data = df.tail(5)[['æ—¥æœŸ', 'å¼€ç›˜', 'æ”¶ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æˆäº¤é‡']]
        for idx, row in recent_data.iterrows():
            print(f"   {row['æ—¥æœŸ'].strftime('%Y-%m-%d')}: å¼€ç›˜Â¥{row['å¼€ç›˜']:.2f}, æ”¶ç›˜Â¥{row['æ”¶ç›˜']:.2f}, æˆäº¤é‡{row['æˆäº¤é‡']:,}")
        
        return True
        
    except Exception as e:
        print(f"âŒ åˆ†æå¤±è´¥: {str(e)}")
        return False

def check_data_for_kronos():
    """æ£€æŸ¥æ•°æ®æ˜¯å¦æ»¡è¶³Kronosè¦æ±‚"""
    print("\nğŸ¤– æ£€æŸ¥æ•°æ®æ˜¯å¦æ»¡è¶³Kronosæ¨¡å‹è¦æ±‚")
    print("=" * 40)
    
    requirements = {
        "æœ€å°å†å²é•¿åº¦": 101,  # lookback_window + predict_window + 1
        "æ¨èå†å²é•¿åº¦": 365 * 2,  # 2å¹´
        "ç†æƒ³å†å²é•¿åº¦": 365 * 5,  # 5å¹´
        "å¿…éœ€å­—æ®µ": ['æ—¥æœŸ', 'å¼€ç›˜', 'æ”¶ç›˜', 'æœ€é«˜', 'æœ€ä½', 'æˆäº¤é‡', 'æˆäº¤é¢']
    }
    
    print("ğŸ“‹ Kronosæ¨¡å‹æ•°æ®è¦æ±‚:")
    for req, value in requirements.items():
        if isinstance(value, int):
            print(f"   {req}: {value} å¤©")
        else:
            print(f"   {req}: {value}")
    
    # æ£€æŸ¥æ ·æœ¬æ•°æ®
    sample_file = Path("data/akshare_data/000001.csv")
    if sample_file.exists():
        df = pd.read_csv(sample_file)
        
        print(f"\nâœ… å½“å‰æ•°æ®çŠ¶æ€:")
        print(f"   å®é™…è®°å½•æ•°: {len(df)} å¤©")
        print(f"   æ˜¯å¦æ»¡è¶³æœ€å°è¦æ±‚: {'âœ… æ˜¯' if len(df) >= requirements['æœ€å°å†å²é•¿åº¦'] else 'âŒ å¦'}")
        print(f"   æ˜¯å¦æ»¡è¶³æ¨èè¦æ±‚: {'âœ… æ˜¯' if len(df) >= requirements['æ¨èå†å²é•¿åº¦'] else 'âŒ å¦'}")
        print(f"   æ˜¯å¦æ»¡è¶³ç†æƒ³è¦æ±‚: {'âœ… æ˜¯' if len(df) >= requirements['ç†æƒ³å†å²é•¿åº¦'] else 'âŒ å¦'}")
        
        # æ£€æŸ¥å­—æ®µ
        missing_fields = [field for field in requirements['å¿…éœ€å­—æ®µ'] if field not in df.columns]
        if missing_fields:
            print(f"   âŒ ç¼ºå°‘å­—æ®µ: {missing_fields}")
        else:
            print(f"   âœ… æ‰€æœ‰å¿…éœ€å­—æ®µéƒ½å­˜åœ¨")
        
        return len(df) >= requirements['æœ€å°å†å²é•¿åº¦'] and len(missing_fields) == 0
    
    return False

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸ” éªŒè¯5å¹´å†å²æ•°æ®ä¸‹è½½ç»“æœ")
    print("=" * 60)
    
    # éªŒè¯akshareæ•°æ®
    akshare_ok = verify_akshare_data()
    
    if akshare_ok:
        # è¯¦ç»†åˆ†æ
        analyze_sample_stock()
        
        # æ£€æŸ¥Kronosè¦æ±‚
        kronos_ready = check_data_for_kronos()
        
        print("\n" + "=" * 60)
        print("ğŸ‰ æ•°æ®éªŒè¯å®Œæˆï¼")
        
        print(f"\nğŸ“Š éªŒè¯ç»“æœ:")
        print(f"   akshareæ•°æ®: {'âœ… å¯ç”¨' if akshare_ok else 'âŒ ä¸å¯ç”¨'}")
        print(f"   Kronoså…¼å®¹: {'âœ… å…¼å®¹' if kronos_ready else 'âŒ ä¸å…¼å®¹'}")
        
        if akshare_ok and kronos_ready:
            print(f"\nğŸ¯ æ•°æ®è´¨é‡è¯„ä¼°: ä¼˜ç§€")
            print(f"   âœ… 5å¹´å®Œæ•´å†å²æ•°æ®")
            print(f"   âœ… 100åªè‚¡ç¥¨æ ·æœ¬")
            print(f"   âœ… æ»¡è¶³Kronosæ¨¡å‹è¦æ±‚")
            print(f"   âœ… æ•°æ®æ ¼å¼æ­£ç¡®")
            
            print(f"\nğŸ”§ åç»­æ­¥éª¤:")
            print(f"   1. ä¸‹è½½Kronosé¢„è®­ç»ƒæ¨¡å‹")
            print(f"   2. åˆ›å»ºæ•°æ®é€‚é…å™¨")
            print(f"   3. æ›´æ–°åº”ç”¨é…ç½®")
            print(f"   4. æµ‹è¯•çœŸå®æ¨¡å‹é¢„æµ‹")
        else:
            print(f"\nâš ï¸ éœ€è¦æ”¹è¿›çš„åœ°æ–¹:")
            if not akshare_ok:
                print(f"   - é‡æ–°ä¸‹è½½akshareæ•°æ®")
            if not kronos_ready:
                print(f"   - æ£€æŸ¥æ•°æ®æ ¼å¼å’Œå­—æ®µ")
    else:
        print("\nâŒ æ•°æ®éªŒè¯å¤±è´¥")
        print("è¯·é‡æ–°è¿è¡Œæ•°æ®ä¸‹è½½è„šæœ¬")

if __name__ == "__main__":
    main()
