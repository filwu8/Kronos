"""
FastAPIåç«¯æœåŠ¡
æä¾›è‚¡ç¥¨é¢„æµ‹APIæ¥å£
"""

from fastapi import FastAPI, HTTPException, BackgroundTasks
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import List, Optional, Dict, Any
import logging
from datetime import datetime
import os

from .prediction_service import get_prediction_service

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# åˆ›å»ºFastAPIåº”ç”¨
app = FastAPI(
    title="Gordon Wang çš„è‚¡ç¥¨é¢„æµ‹API",
    description="åŸºäºRTX 5090 GPUåŠ é€Ÿçš„æ™ºèƒ½è‚¡ç¥¨ä»·æ ¼é¢„æµ‹æœåŠ¡",
    version="1.0.0"
)

# æ·»åŠ CORSä¸­é—´ä»¶
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ç”Ÿäº§ç¯å¢ƒä¸­åº”è¯¥é™åˆ¶å…·ä½“åŸŸå
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å…¨å±€å˜é‡
prediction_service = None


# Pydanticæ¨¡å‹å®šä¹‰
class PredictionRequest(BaseModel):
    """é¢„æµ‹è¯·æ±‚æ¨¡å‹"""
    stock_code: str = Field(..., description="è‚¡ç¥¨ä»£ç ï¼Œå¦‚ï¼š000001ã€600000")
    period: str = Field("1y", description="å†å²æ•°æ®å‘¨æœŸï¼š1y, 2y, 5y")
    pred_len: int = Field(30, ge=1, le=120, description="é¢„æµ‹å¤©æ•°ï¼Œ1-120å¤©")
    lookback: int = Field(1000, ge=50, le=5000, description="å†å²æ•°æ®é•¿åº¦ï¼ŒRTX 5090æ”¯æŒå¤§æ•°æ®é‡")
    temperature: float = Field(1.0, ge=0.1, le=2.0, description="é‡‡æ ·æ¸©åº¦")
    top_p: float = Field(0.9, ge=0.1, le=1.0, description="æ ¸é‡‡æ ·æ¦‚ç‡")
    sample_count: int = Field(1, ge=1, le=5, description="é‡‡æ ·æ¬¡æ•°")


class BatchPredictionRequest(BaseModel):
    """æ‰¹é‡é¢„æµ‹è¯·æ±‚æ¨¡å‹"""
    stock_codes: List[str] = Field(..., description="è‚¡ç¥¨ä»£ç åˆ—è¡¨")
    period: str = Field("1y", description="å†å²æ•°æ®å‘¨æœŸ")
    pred_len: int = Field(30, ge=1, le=60, description="é¢„æµ‹å¤©æ•°")


class StockInfo(BaseModel):
    """è‚¡ç¥¨ä¿¡æ¯æ¨¡å‹"""
    code: str
    name: str
    market: str
    source: str


class PredictionSummary(BaseModel):
    """é¢„æµ‹æ‘˜è¦æ¨¡å‹"""
    current_price: float
    predicted_price: float
    change_amount: float
    change_percent: float
    trend: str
    volatility: float
    prediction_days: int
    confidence: str


class PredictionResponse(BaseModel):
    """é¢„æµ‹å“åº”æ¨¡å‹"""
    success: bool
    error: Optional[str] = None
    data: Optional[Dict[str, Any]] = None


# å¯åŠ¨äº‹ä»¶
@app.on_event("startup")
async def startup_event():
    """åº”ç”¨å¯åŠ¨æ—¶åˆå§‹åŒ–"""
    global prediction_service
    
    logger.info("æ­£åœ¨å¯åŠ¨è‚¡ç¥¨é¢„æµ‹æœåŠ¡...")
    
    # å¼ºåˆ¶ä½¿ç”¨çœŸå®æ•°æ®æ¨¡å¼
    use_mock = False  # å¼ºåˆ¶å…³é—­æ¨¡æ‹Ÿæ¨¡å¼

    # GPUæ£€æµ‹å’Œé…ç½®
    import torch
    if torch.cuda.is_available():
        gpu_name = torch.cuda.get_device_name(0)
        gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
        logger.info(f"æ£€æµ‹åˆ°GPU: {gpu_name}")
        logger.info(f"GPUå†…å­˜: {gpu_memory:.1f} GB")

        # æµ‹è¯•GPUå…¼å®¹æ€§
        try:
            test_tensor = torch.randn(10, 10, device="cuda")
            _ = torch.mm(test_tensor, test_tensor)
            device = "cuda"
            logger.info("âœ… GPUå…¼å®¹æ€§æµ‹è¯•é€šè¿‡ï¼Œä½¿ç”¨GPU")
        except Exception as e:
            device = "cpu"
            logger.warning(f"âš ï¸ GPUå…¼å®¹æ€§é—®é¢˜ï¼Œä½¿ç”¨CPU: {str(e)}")
            logger.info("ğŸ’¡ RTX 5090éœ€è¦æ›´æ–°çš„PyTorchç‰ˆæœ¬æ”¯æŒ")
    else:
        device = "cpu"
        logger.info("æœªæ£€æµ‹åˆ°GPUï¼Œä½¿ç”¨CPU")

    # å…è®¸ç¯å¢ƒå˜é‡è¦†ç›–
    device = os.getenv("DEVICE", device)

    # CPUä¼˜åŒ–é…ç½®
    if device == "cpu":
        torch.set_num_threads(8)  # ä½¿ç”¨8ä¸ªCPUçº¿ç¨‹
        logger.info("ğŸš€ CPUä¼˜åŒ–ï¼šä½¿ç”¨8çº¿ç¨‹å¹¶è¡Œè®¡ç®—")

    try:
        prediction_service = get_prediction_service(device=device, use_mock=use_mock)
        logger.info("é¢„æµ‹æœåŠ¡å¯åŠ¨æˆåŠŸ - ä½¿ç”¨çœŸå®æ•°æ®æ¨¡å¼")
    except Exception as e:
        logger.error(f"é¢„æµ‹æœåŠ¡å¯åŠ¨å¤±è´¥: {str(e)}")
        # å³ä½¿å¤±è´¥ä¹Ÿè¦å¯åŠ¨ï¼Œä½†ä»å°è¯•çœŸå®æ¨¡å¼
        prediction_service = get_prediction_service(device="cpu", use_mock=False)


# APIè·¯ç”±
@app.get("/")
async def root():
    """æ ¹è·¯å¾„"""
    return {
        "message": "Kronosè‚¡ç¥¨é¢„æµ‹API",
        "version": "1.0.0",
        "status": "running",
        "timestamp": datetime.now().isoformat()
    }


@app.get("/health")
async def health_check():
    """å¥åº·æ£€æŸ¥"""
    global prediction_service
    
    if prediction_service is None:
        raise HTTPException(status_code=503, detail="é¢„æµ‹æœåŠ¡æœªåˆå§‹åŒ–")
    
    status = prediction_service.get_model_status()
    
    return {
        "status": "healthy",
        "model_status": status,
        "timestamp": datetime.now().isoformat()
    }


@app.post("/predict", response_model=PredictionResponse)
async def predict_stock(request: PredictionRequest):
    """
    é¢„æµ‹å•åªè‚¡ç¥¨ä»·æ ¼
    """
    global prediction_service
    
    if prediction_service is None:
        raise HTTPException(status_code=503, detail="é¢„æµ‹æœåŠ¡æœªåˆå§‹åŒ–")
    
    try:
        logger.info(f"æ”¶åˆ°é¢„æµ‹è¯·æ±‚: {request.stock_code}")
        
        # æ‰§è¡Œé¢„æµ‹
        result = prediction_service.predict_stock(
            stock_code=request.stock_code,
            period=request.period,
            pred_len=request.pred_len,
            lookback=request.lookback,
            T=request.temperature,
            top_p=request.top_p,
            sample_count=request.sample_count
        )
        
        if not result['success']:
            raise HTTPException(status_code=400, detail=result['error'])
        
        return PredictionResponse(**result)
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"é¢„æµ‹è¯·æ±‚å¤„ç†å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å†…éƒ¨æœåŠ¡å™¨é”™è¯¯: {str(e)}")


@app.post("/predict/batch")
async def batch_predict(request: BatchPredictionRequest):
    """
    æ‰¹é‡é¢„æµ‹å¤šåªè‚¡ç¥¨
    """
    global prediction_service
    
    if prediction_service is None:
        raise HTTPException(status_code=503, detail="é¢„æµ‹æœåŠ¡æœªåˆå§‹åŒ–")
    
    if len(request.stock_codes) > 10:
        raise HTTPException(status_code=400, detail="æ‰¹é‡é¢„æµ‹æœ€å¤šæ”¯æŒ10åªè‚¡ç¥¨")
    
    try:
        logger.info(f"æ”¶åˆ°æ‰¹é‡é¢„æµ‹è¯·æ±‚: {request.stock_codes}")
        
        # æ‰§è¡Œæ‰¹é‡é¢„æµ‹
        results = prediction_service.batch_predict(
            stock_codes=request.stock_codes,
            period=request.period,
            pred_len=request.pred_len
        )
        
        return {
            "success": True,
            "data": results,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"æ‰¹é‡é¢„æµ‹è¯·æ±‚å¤„ç†å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"å†…éƒ¨æœåŠ¡å™¨é”™è¯¯: {str(e)}")


@app.get("/stocks/{stock_code}/info")
async def get_stock_info(stock_code: str):
    """
    è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯
    """
    global prediction_service
    
    if prediction_service is None:
        raise HTTPException(status_code=503, detail="é¢„æµ‹æœåŠ¡æœªåˆå§‹åŒ–")
    
    try:
        info = prediction_service.data_fetcher.get_stock_info(stock_code)
        return {
            "success": True,
            "data": info,
            "timestamp": datetime.now().isoformat()
        }
        
    except Exception as e:
        logger.error(f"è·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–è‚¡ç¥¨ä¿¡æ¯å¤±è´¥: {str(e)}")


@app.get("/stocks/{stock_code}/history")
async def get_stock_history(
    stock_code: str, 
    period: str = "1y",
    limit: int = 100
):
    """
    è·å–è‚¡ç¥¨å†å²æ•°æ®
    """
    global prediction_service
    
    if prediction_service is None:
        raise HTTPException(status_code=503, detail="é¢„æµ‹æœåŠ¡æœªåˆå§‹åŒ–")
    
    try:
        df = prediction_service.data_fetcher.fetch_stock_data(stock_code, period=period)
        
        if df is None or df.empty:
            raise HTTPException(status_code=404, detail=f"æœªæ‰¾åˆ°è‚¡ç¥¨æ•°æ®: {stock_code}")
        
        # é™åˆ¶è¿”å›æ•°æ®é‡
        if len(df) > limit:
            df = df.tail(limit)
        
        # è½¬æ¢ä¸ºå­—å…¸æ ¼å¼
        data = df.reset_index().to_dict('records')
        
        return {
            "success": True,
            "data": {
                "stock_code": stock_code,
                "period": period,
                "count": len(data),
                "history": data
            },
            "timestamp": datetime.now().isoformat()
        }
        
    except HTTPException:
        raise
    except Exception as e:
        logger.error(f"è·å–å†å²æ•°æ®å¤±è´¥: {str(e)}")
        raise HTTPException(status_code=500, detail=f"è·å–å†å²æ•°æ®å¤±è´¥: {str(e)}")


@app.get("/model/status")
async def get_model_status():
    """
    è·å–æ¨¡å‹çŠ¶æ€ä¿¡æ¯
    """
    global prediction_service
    
    if prediction_service is None:
        return {
            "model_loaded": False,
            "error": "é¢„æµ‹æœåŠ¡æœªåˆå§‹åŒ–"
        }
    
    status = prediction_service.get_model_status()
    return status


@app.get("/api/docs")
async def get_api_docs():
    """
    APIæ–‡æ¡£ä¿¡æ¯
    """
    return {
        "title": "Kronosè‚¡ç¥¨é¢„æµ‹API",
        "description": "åŸºäºKronosæ¨¡å‹çš„Aè‚¡è‚¡ç¥¨ä»·æ ¼é¢„æµ‹æœåŠ¡",
        "version": "1.0.0",
        "endpoints": {
            "POST /predict": "é¢„æµ‹å•åªè‚¡ç¥¨ä»·æ ¼",
            "POST /predict/batch": "æ‰¹é‡é¢„æµ‹å¤šåªè‚¡ç¥¨",
            "GET /stocks/{code}/info": "è·å–è‚¡ç¥¨åŸºæœ¬ä¿¡æ¯",
            "GET /stocks/{code}/history": "è·å–è‚¡ç¥¨å†å²æ•°æ®",
            "GET /health": "å¥åº·æ£€æŸ¥",
            "GET /model/status": "æ¨¡å‹çŠ¶æ€"
        },
        "examples": {
            "stock_codes": ["000001", "600000", "000002.SZ", "600036.SS"],
            "prediction_request": {
                "stock_code": "000001",
                "period": "1y",
                "pred_len": 30,
                "temperature": 1.0,
                "top_p": 0.9
            }
        }
    }


# é”™è¯¯å¤„ç†
@app.exception_handler(404)
async def not_found_handler(request, exc):
    return {
        "success": False,
        "error": "æ¥å£ä¸å­˜åœ¨",
        "timestamp": datetime.now().isoformat()
    }


@app.exception_handler(500)
async def internal_error_handler(request, exc):
    return {
        "success": False,
        "error": "å†…éƒ¨æœåŠ¡å™¨é”™è¯¯",
        "timestamp": datetime.now().isoformat()
    }


if __name__ == "__main__":
    import uvicorn
    
    # å¯åŠ¨æœåŠ¡
    uvicorn.run(
        "api:app",
        host="0.0.0.0",
        port=8000,
        reload=True,
        log_level="info"
    )
