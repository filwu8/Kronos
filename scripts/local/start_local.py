#!/usr/bin/env python3
"""
RTX 5090 GPUåŠ é€Ÿè‚¡ç¥¨é¢„æµ‹ç³»ç»Ÿ - æœ¬åœ°å¯åŠ¨è„šæœ¬
"""

import os
import sys
import time
import subprocess
import multiprocessing
from pathlib import Path

def check_environment():
    """æ£€æŸ¥è¿è¡Œç¯å¢ƒ"""
    print("ğŸ” æ£€æŸ¥è¿è¡Œç¯å¢ƒ...")
    
    # æ£€æŸ¥Pythonç‰ˆæœ¬
    python_version = sys.version_info
    if python_version.major < 3 or python_version.minor < 8:
        print(f"âŒ Pythonç‰ˆæœ¬è¿‡ä½: {python_version.major}.{python_version.minor}")
        print("   éœ€è¦Python 3.8+")
        return False
    
    print(f"âœ… Pythonç‰ˆæœ¬: {python_version.major}.{python_version.minor}.{python_version.micro}")
    
    # æ£€æŸ¥å¿…è¦çš„åŒ…
    required_packages = [
        'torch', 'fastapi', 'streamlit', 'pandas', 'numpy', 'plotly'
    ]
    
    missing_packages = []
    for package in required_packages:
        try:
            __import__(package)
            print(f"âœ… {package}: å·²å®‰è£…")
        except ImportError:
            missing_packages.append(package)
            print(f"âŒ {package}: æœªå®‰è£…")
    
    if missing_packages:
        print(f"\nğŸ“¦ å®‰è£…ç¼ºå¤±çš„åŒ…:")
        print(f"   pip install {' '.join(missing_packages)}")
        return False
    
    return True

def check_gpu():
    """æ£€æŸ¥GPUçŠ¶æ€"""
    print("\nğŸš€ æ£€æŸ¥GPUçŠ¶æ€...")
    
    try:
        import torch
        print(f"PyTorchç‰ˆæœ¬: {torch.__version__}")
        
        if torch.cuda.is_available():
            gpu_name = torch.cuda.get_device_name(0)
            gpu_memory = torch.cuda.get_device_properties(0).total_memory / 1024**3
            print(f"âœ… GPU: {gpu_name}")
            print(f"âœ… æ˜¾å­˜: {gpu_memory:.1f} GB")
            
            # æµ‹è¯•GPUè®¡ç®—
            try:
                x = torch.randn(100, 100, device='cuda')
                y = torch.mm(x, x)
                print("âœ… GPUè®¡ç®—æµ‹è¯•é€šè¿‡")
                return True
            except Exception as e:
                print(f"âŒ GPUè®¡ç®—æµ‹è¯•å¤±è´¥: {str(e)}")
                return False
        else:
            print("âš ï¸ CUDAä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨CPUæ¨¡å¼")
            return False
    except ImportError:
        print("âŒ PyTorchæœªå®‰è£…")
        return False

def setup_environment():
    """è®¾ç½®ç¯å¢ƒå˜é‡"""
    print("\nâš™ï¸ è®¾ç½®ç¯å¢ƒå˜é‡...")
    
    # åŸºç¡€è·¯å¾„
    base_dir = Path(__file__).parent.parent.parent
    volumes_dir = base_dir / "volumes"
    
    # è®¾ç½®ç¯å¢ƒå˜é‡
    env_vars = {
        "PYTHONPATH": f"{base_dir};{volumes_dir}",
        "DEPLOYMENT_MODE": "local",
        "API_HOST": "0.0.0.0",
        "API_PORT": "8000",
        "STREAMLIT_HOST": "0.0.0.0", 
        "STREAMLIT_PORT": "8501",
        "USE_MOCK": "false",
        "AUTO_DOWNLOAD_DATA": "true"
    }
    
    for key, value in env_vars.items():
        os.environ[key] = value
        print(f"   {key}={value}")

def start_api_service():
    """å¯åŠ¨APIæœåŠ¡"""
    print("ğŸ”Œ å¯åŠ¨APIæœåŠ¡...")
    
    try:
        # åˆ‡æ¢åˆ°é¡¹ç›®æ ¹ç›®å½•
        base_dir = Path(__file__).parent.parent.parent
        os.chdir(base_dir)
        
        # å¯åŠ¨uvicorn
        subprocess.run([
            sys.executable, "-m", "uvicorn",
            "app.api:app",
            "--host", "0.0.0.0",
            "--port", "8000",
            "--reload"
        ])
    except KeyboardInterrupt:
        print("APIæœåŠ¡å·²åœæ­¢")
    except Exception as e:
        print(f"âŒ APIæœåŠ¡å¯åŠ¨å¤±è´¥: {str(e)}")

def start_streamlit_service():
    """å¯åŠ¨StreamlitæœåŠ¡"""
    print("ğŸ¨ å¯åŠ¨StreamlitæœåŠ¡...")
    
    try:
        # åˆ‡æ¢åˆ°é¡¹ç›®æ ¹ç›®å½•
        base_dir = Path(__file__).parent.parent.parent
        os.chdir(base_dir)
        
        # å¯åŠ¨streamlit
        subprocess.run([
            sys.executable, "-m", "streamlit", "run",
            "app/streamlit_app.py",
            "--server.address", "0.0.0.0",
            "--server.port", "8501"
        ])
    except KeyboardInterrupt:
        print("StreamlitæœåŠ¡å·²åœæ­¢")
    except Exception as e:
        print(f"âŒ StreamlitæœåŠ¡å¯åŠ¨å¤±è´¥: {str(e)}")

def wait_for_services():
    """ç­‰å¾…æœåŠ¡å¯åŠ¨"""
    print("â³ ç­‰å¾…æœåŠ¡å¯åŠ¨...")
    
    import requests
    
    # ç­‰å¾…APIæœåŠ¡
    for i in range(30):
        try:
            response = requests.get("http://localhost:8000/health", timeout=1)
            if response.status_code == 200:
                print("âœ… APIæœåŠ¡å·²å¯åŠ¨")
                break
        except:
            pass
        time.sleep(1)
    else:
        print("âš ï¸ APIæœåŠ¡å¯åŠ¨è¶…æ—¶")
    
    # ç­‰å¾…StreamlitæœåŠ¡
    for i in range(30):
        try:
            response = requests.get("http://localhost:8501", timeout=1)
            if response.status_code == 200:
                print("âœ… StreamlitæœåŠ¡å·²å¯åŠ¨")
                break
        except:
            pass
        time.sleep(1)
    else:
        print("âš ï¸ StreamlitæœåŠ¡å¯åŠ¨è¶…æ—¶")

def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ RTX 5090 GPUåŠ é€Ÿè‚¡ç¥¨é¢„æµ‹ç³»ç»Ÿ - æœ¬åœ°ç‰ˆæœ¬")
    print("=" * 60)
    
    # 1. æ£€æŸ¥ç¯å¢ƒ
    if not check_environment():
        print("\nâŒ ç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œè¯·è§£å†³ä¸Šè¿°é—®é¢˜åé‡è¯•")
        return
    
    # 2. æ£€æŸ¥GPU
    gpu_available = check_gpu()
    if gpu_available:
        os.environ["DEVICE"] = "cuda"
    else:
        os.environ["DEVICE"] = "cpu"
    
    # 3. è®¾ç½®ç¯å¢ƒ
    setup_environment()
    
    print("\nğŸŒ æœåŠ¡åœ°å€:")
    print("   å‰ç«¯ç•Œé¢: http://localhost:8501")
    print("   APIæ–‡æ¡£: http://localhost:8000/docs")
    print("   å¥åº·æ£€æŸ¥: http://localhost:8000/health")
    print("\næŒ‰ Ctrl+C åœæ­¢æ‰€æœ‰æœåŠ¡")
    
    try:
        # 4. å¯åŠ¨æœåŠ¡
        api_process = multiprocessing.Process(target=start_api_service)
        streamlit_process = multiprocessing.Process(target=start_streamlit_service)
        
        api_process.start()
        time.sleep(3)  # ç­‰å¾…APIæœåŠ¡å¯åŠ¨
        streamlit_process.start()
        
        # 5. ç­‰å¾…æœåŠ¡å°±ç»ª
        wait_for_services()
        
        print("\nâœ… æ‰€æœ‰æœåŠ¡å·²å¯åŠ¨!")
        print("ğŸ‰ ç³»ç»Ÿå·²å°±ç»ªï¼Œå¯ä»¥å¼€å§‹ä½¿ç”¨")
        
        # 6. ç­‰å¾…è¿›ç¨‹ç»“æŸ
        api_process.join()
        streamlit_process.join()
        
    except KeyboardInterrupt:
        print("\nğŸ›‘ æ­£åœ¨åœæ­¢æœåŠ¡...")
        if 'api_process' in locals() and api_process.is_alive():
            api_process.terminate()
            api_process.join()
        if 'streamlit_process' in locals() and streamlit_process.is_alive():
            streamlit_process.terminate()
            streamlit_process.join()
        print("âœ… æ‰€æœ‰æœåŠ¡å·²åœæ­¢")

if __name__ == "__main__":
    multiprocessing.freeze_support()
    main()
